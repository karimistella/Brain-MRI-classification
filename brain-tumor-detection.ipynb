{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-31T08:07:30.024092Z","iopub.execute_input":"2022-05-31T08:07:30.024696Z","iopub.status.idle":"2022-05-31T08:07:30.055207Z","shell.execute_reply.started":"2022-05-31T08:07:30.024662Z","shell.execute_reply":"2022-05-31T08:07:30.053951Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport pathlib\nimport PIL\nimport PIL.Image\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\nimport matplotlib.pyplot as plt\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential","metadata":{"execution":{"iopub.status.busy":"2022-05-31T08:29:55.546037Z","iopub.execute_input":"2022-05-31T08:29:55.546410Z","iopub.status.idle":"2022-05-31T08:29:55.553438Z","shell.execute_reply.started":"2022-05-31T08:29:55.546379Z","shell.execute_reply":"2022-05-31T08:29:55.552062Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"dataset_url = \"/kaggle/input/brain-mri-images-for-brain-tumor-detection/brain_tumor_dataset\"\ndata_dir = pathlib.Path(dataset_url)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T08:07:40.494463Z","iopub.execute_input":"2022-05-31T08:07:40.495343Z","iopub.status.idle":"2022-05-31T08:07:40.498911Z","shell.execute_reply.started":"2022-05-31T08:07:40.495303Z","shell.execute_reply":"2022-05-31T08:07:40.498293Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"#parameters for the loader\nbatch_size = 32 #incase we need to run the images in batches\nimg_height = 180\nimg_width = 180","metadata":{"execution":{"iopub.status.busy":"2022-05-31T08:07:41.424709Z","iopub.execute_input":"2022-05-31T08:07:41.425675Z","iopub.status.idle":"2022-05-31T08:07:41.430396Z","shell.execute_reply.started":"2022-05-31T08:07:41.425631Z","shell.execute_reply":"2022-05-31T08:07:41.429205Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"#use a validation split 80% training and 20% testing\ntrain_ds = tf.keras.utils.image_dataset_from_directory( data_dir,\n                                                        validation_split=0.2,\n                                                        subset=\"training\",\n                                                        seed=123,\n                                                        image_size=(img_height, img_width),\n                                                        batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T08:07:42.686760Z","iopub.execute_input":"2022-05-31T08:07:42.687779Z","iopub.status.idle":"2022-05-31T08:07:42.812004Z","shell.execute_reply.started":"2022-05-31T08:07:42.687737Z","shell.execute_reply":"2022-05-31T08:07:42.811010Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"val_ds = tf.keras.utils.image_dataset_from_directory(\n  data_dir,\n  validation_split=0.2,\n  subset=\"validation\",\n  seed=123,\n  image_size=(img_height, img_width),\n  batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T08:07:43.725530Z","iopub.execute_input":"2022-05-31T08:07:43.726231Z","iopub.status.idle":"2022-05-31T08:07:43.846734Z","shell.execute_reply.started":"2022-05-31T08:07:43.726168Z","shell.execute_reply":"2022-05-31T08:07:43.845720Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"class_names = train_ds.class_names\nprint(class_names)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T08:07:44.802140Z","iopub.execute_input":"2022-05-31T08:07:44.802498Z","iopub.status.idle":"2022-05-31T08:07:44.807557Z","shell.execute_reply.started":"2022-05-31T08:07:44.802469Z","shell.execute_reply":"2022-05-31T08:07:44.806934Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"#visualize the data\nplt.figure(figsize=(10, 10))\nfor images, labels in train_ds.take(1):\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title(class_names[labels[i]])\n        plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2022-05-31T08:07:46.770773Z","iopub.execute_input":"2022-05-31T08:07:46.771486Z","iopub.status.idle":"2022-05-31T08:07:47.791589Z","shell.execute_reply.started":"2022-05-31T08:07:46.771453Z","shell.execute_reply":"2022-05-31T08:07:47.790585Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"#standardize the data\nnormalization_layer = tf.keras.layers.Rescaling(1./255)\n\nnormalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\nimage_batch, labels_batch = next(iter(normalized_ds))\nfirst_image = image_batch[0]\n# Notice the pixel values are now in `[0,1]`.\nprint(np.min(first_image), np.max(first_image))","metadata":{"execution":{"iopub.status.busy":"2022-05-31T08:07:49.843637Z","iopub.execute_input":"2022-05-31T08:07:49.844615Z","iopub.status.idle":"2022-05-31T08:07:50.082746Z","shell.execute_reply.started":"2022-05-31T08:07:49.844580Z","shell.execute_reply":"2022-05-31T08:07:50.082097Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"AUTOTUNE = tf.data.AUTOTUNE\n\ntrain_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\nval_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T08:07:51.154306Z","iopub.execute_input":"2022-05-31T08:07:51.154675Z","iopub.status.idle":"2022-05-31T08:07:51.163419Z","shell.execute_reply.started":"2022-05-31T08:07:51.154644Z","shell.execute_reply":"2022-05-31T08:07:51.162536Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"#train a model\nnum_classes = 2\n\nmodel = tf.keras.Sequential([\n  tf.keras.layers.Rescaling(1./255),\n  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n  tf.keras.layers.MaxPooling2D(),\n  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n  tf.keras.layers.MaxPooling2D(),\n  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n  tf.keras.layers.MaxPooling2D(),\n  tf.keras.layers.Flatten(),\n  tf.keras.layers.Dense(128, activation='relu'),\n  tf.keras.layers.Dense(num_classes)\n])","metadata":{"execution":{"iopub.status.busy":"2022-05-31T08:07:53.243170Z","iopub.execute_input":"2022-05-31T08:07:53.243567Z","iopub.status.idle":"2022-05-31T08:07:53.266117Z","shell.execute_reply.started":"2022-05-31T08:07:53.243537Z","shell.execute_reply":"2022-05-31T08:07:53.265184Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"model.compile(\n  optimizer='adam',\n  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n  metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-05-31T08:07:55.434735Z","iopub.execute_input":"2022-05-31T08:07:55.435363Z","iopub.status.idle":"2022-05-31T08:07:55.445863Z","shell.execute_reply.started":"2022-05-31T08:07:55.435324Z","shell.execute_reply":"2022-05-31T08:07:55.445053Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"epochs = 10\nhistory = model.fit(\n  train_ds,\n  validation_data=val_ds,\n  epochs= epochs\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T08:07:56.834702Z","iopub.execute_input":"2022-05-31T08:07:56.835077Z","iopub.status.idle":"2022-05-31T08:08:16.513637Z","shell.execute_reply.started":"2022-05-31T08:07:56.835047Z","shell.execute_reply":"2022-05-31T08:08:16.512914Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"#view all the layers of the model\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-31T08:08:37.611338Z","iopub.execute_input":"2022-05-31T08:08:37.611891Z","iopub.status.idle":"2022-05-31T08:08:37.616969Z","shell.execute_reply.started":"2022-05-31T08:08:37.611840Z","shell.execute_reply":"2022-05-31T08:08:37.616271Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"#Create plots of loss and accuracy on the training and validation sets\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-31T08:08:42.570998Z","iopub.execute_input":"2022-05-31T08:08:42.572040Z","iopub.status.idle":"2022-05-31T08:08:42.898880Z","shell.execute_reply.started":"2022-05-31T08:08:42.572003Z","shell.execute_reply":"2022-05-31T08:08:42.897916Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"markdown","source":"We can notice a very big difference in the training and validation accuracy which is a sign of overfitting.\nThis could be because the model is learning using a a small number of training examples. \nTo combat overfitting, we will use data augmentation.\n\nData augmentation takes the approach of generating additional training data from your existing examples by augmenting them using random transformations that yield believable-looking images. This helps expose the model to more aspects of the data and generalize better.","metadata":{}},{"cell_type":"code","source":"#data augmentation using randomflip, randomzoom and random rotation\ndata_augmentation = keras.Sequential(\n  [\n    layers.RandomFlip(\"horizontal\",\n                      input_shape=(img_height,\n                                  img_width,\n                                  3)),\n    layers.RandomRotation(0.1),\n    layers.RandomZoom(0.1),\n  ]\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T08:19:24.786460Z","iopub.execute_input":"2022-05-31T08:19:24.786907Z","iopub.status.idle":"2022-05-31T08:19:24.918905Z","shell.execute_reply.started":"2022-05-31T08:19:24.786843Z","shell.execute_reply":"2022-05-31T08:19:24.917989Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"#visualize few augmented images\nplt.figure(figsize=(10, 10))\nfor images, _ in train_ds.take(1):\n    for i in range(9):\n        augmented_images = data_augmentation(images)\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n        plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2022-05-31T08:20:43.004145Z","iopub.execute_input":"2022-05-31T08:20:43.004876Z","iopub.status.idle":"2022-05-31T08:20:44.591395Z","shell.execute_reply.started":"2022-05-31T08:20:43.004812Z","shell.execute_reply":"2022-05-31T08:20:44.590509Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"markdown","source":"To further reduce overfitting will introduce dropout regularization to the network.\n\nWhen you apply dropout to a layer, it randomly drops out (by setting the activation to zero) a number of output units from the layer during the training process. Dropout takes a fractional number as its input value, in the form such as 0.1, 0.2, 0.4, etc. This means dropping out 10%, 20% or 40% of the output units randomly from the applied layer.","metadata":{}},{"cell_type":"code","source":"model = Sequential([\n  data_augmentation,\n  layers.Rescaling(1./255),\n  layers.Conv2D(16, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(32, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(64, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Dropout(0.2), #dropout layer\n  layers.Flatten(),\n  layers.Dense(128, activation='relu'),\n  layers.Dense(num_classes)\n])","metadata":{"execution":{"iopub.status.busy":"2022-05-31T08:30:00.290974Z","iopub.execute_input":"2022-05-31T08:30:00.291531Z","iopub.status.idle":"2022-05-31T08:30:00.491745Z","shell.execute_reply.started":"2022-05-31T08:30:00.291484Z","shell.execute_reply":"2022-05-31T08:30:00.490843Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"#compile and train the model\nmodel.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-05-31T08:30:33.335610Z","iopub.execute_input":"2022-05-31T08:30:33.336030Z","iopub.status.idle":"2022-05-31T08:30:33.348214Z","shell.execute_reply.started":"2022-05-31T08:30:33.335996Z","shell.execute_reply":"2022-05-31T08:30:33.347221Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"#model summary\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-31T08:30:50.395444Z","iopub.execute_input":"2022-05-31T08:30:50.396236Z","iopub.status.idle":"2022-05-31T08:30:50.401913Z","shell.execute_reply.started":"2022-05-31T08:30:50.396194Z","shell.execute_reply":"2022-05-31T08:30:50.401222Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"epochs = 15\nhistory = model.fit(\n  train_ds,\n  validation_data=val_ds,\n  epochs=epochs\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T08:31:22.244852Z","iopub.execute_input":"2022-05-31T08:31:22.245436Z","iopub.status.idle":"2022-05-31T08:31:55.438242Z","shell.execute_reply.started":"2022-05-31T08:31:22.245398Z","shell.execute_reply":"2022-05-31T08:31:55.437491Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"#visualize training results\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-31T08:32:36.266521Z","iopub.execute_input":"2022-05-31T08:32:36.266935Z","iopub.status.idle":"2022-05-31T08:32:36.566725Z","shell.execute_reply.started":"2022-05-31T08:32:36.266903Z","shell.execute_reply":"2022-05-31T08:32:36.565890Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}